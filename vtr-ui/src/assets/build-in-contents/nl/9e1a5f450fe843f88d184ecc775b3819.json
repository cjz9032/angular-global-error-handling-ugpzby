{"Results":{"Id":"9e1a5f450fe843f88d184ecc775b3819","Template":"Article","Title":"Met slimmere gegevens kunnen boeren zich sneller aan de klimaatverandering aanpassen","Image":"","Body":"<p style=\"margin: 12pt 0in;\"><span>Stel je eens voor dat je een bepaalde taak alleen kunt uitvoeren door een torenhoge stapel papieren te sorteren en te doorzoeken, waarbij je elke bladzijde moet lezen om aan het einde van de werkdag dat enige stukje belangrijke informatie eruit te kunnen pikken. </span><span></span><span>Na uren sorteren ben je eindelijk door de stapel papier heen. Dat ging goed toch? Maar dat duurt niet lang. De volgende dag wordt opnieuw om een belangrijk stukje informatie gevraagd, net op het moment dat er een nieuwe stapel op je bureau terechtkomt. Zo begint alles dus weer van voor af aan. En de volgende dag opnieuw. En daarna weer.</span></p> \n<p style=\"margin: 12pt 0in;\"><span>Voor datawetenschappers is dit geen hypothetisch geval. Het is de praktijk, hoewel het meestal gaat om bergen digitale informatie in plaats van papier.</span></p> \n<p style=\"margin: 12pt 0in 0.0001pt;\"><span>Vooruitgang in AI, met name op het gebied van machine learning, kan de effici</span><span>ë</span><span>ntie van dit proces verbeteren door de benodigde microscopische en zelfs macroscopische gegevens naar boven te halen. </span><span></span><span>De meeste verzamelde gegevens zijn onbetekenend, <em>gewone</em> gegevens die kunnen worden gecomprimeerd en opgeslagen totdat ze weer nodig zijn. Andere kunnen echter duiden op beginnende bedreigingen. Dat zijn <em>slimme</em> gegevens die vragen om een reactie. Zonder slimme gegevens en computertechnologie kan de verwerking van sommige gegevens weken of zelfs maanden duren. De overweldigende stortvloed aan gegevens is zowel de tegenstander <em>als</em> de redder voor datawetenschappers.</span></p> \n<p style=\"margin: 12pt 0in 0.0001pt; text-align: center;\"><span><img alt=\"\" src=\"assets/build-in-contents/images/ThinkStation.png\" style=\"color: #000000; height: 308px; width: 600px; text-align: center;\"></span></p> \n<p style=\"margin: 12pt 0in;\"><span>En we krijgen te maken met big data zodra we grote problemen willen aanpakken, zoals de wereldwijde voedselvoorziening.</span></p> \n<p><span>Opengewerkte afbeelding van de ThinkStation P920</span></p> \n<p style=\"margin: 12pt 0in;\"><span>De groeiende wereldbevolking en toenemende verstedelijking leiden tot schaarste van voedsel, water, energie en akkerland. Daarom is het belangrijk dat we de uitdagingen die ons te wachten staan, bestuderen en begrijpen. Dit nu net waar de Geospatial Analytics-onderzoekers van de North Carolina State University de afgelopen jaren aan hebben gewerkt. Met slimme gegevens en artificial intelligence identificeren NCSU-onderzoekers op voorhand landbouwgebieden en gewassen die geraakt zullen worden door klimaatverandering, bijvoorbeeld door overstromingen of droogte.</span></p> \n<p style=\"margin: 12pt 0in;\"><span>Terwijl landbouwgronden verdwijnen en de vraag naar voedsel toeneemt, passen deze onderzoekers slimmere, gegevensgestuurde digitale landbouwoplossingen toe om de productie van gewassen te verhogen en daarbij het water- en energieverbruik te optimaliseren. Boeren hebben zo snel mogelijk bruikbare kennis nodig die helpt om voedsel van de beste kwaliteit op tafel te krijgen.</span></p> \n<p style=\"margin: 12pt 0in;\"><span>Ruimtevaartorganisaties zoals de NASA verzamelen tientallen terabytes aan gegevens van satellieten die de aarde observeren en daarnaast nog eens petabytes aan gegevens van klimaatsimulaties en doorlopende waarnemingen van miljarden verspreide sensoren. Het is niet genoeg om de gegevens uit al deze bronnen samen te brengen en vervolgens traditionele offline analyses erop toe te passen als we het hoofd willen bieden aan de dagelijkse uitdagingen waarmee boeren te maken hebben. We moeten de belangrijkste informatie effici</span><span>ë</span><span>nt en vrijwel in realtime boven water halen. Dan kan dit leiden tot betere oogsten en een beter milieubehoud en tot minder verstoring van de wereldwijde voedselproductie bij fluctuerende omgevingsomstandigheden.</span></p> \n<p style=\"margin: 12pt 0in; text-align: center;\"><span><img alt=\"\" src=\"assets/build-in-contents/images/NASA.jpg\" style=\"color: #000000; height: 400px; width: 600px; text-align: center;\"></span></p> \n<p><span>De Earth Science-satellietvloot van de NASA</span></p> \n<p style=\"margin: 12pt 0in;\"><span>Doordat het team werd overspoeld door gegevens, had het behoefte aan een oplossing voor zowel realtime als offline analyse met voldoende rekenkracht om onmiddellijk feedback te kunnen geven en om gegevens te kunnen comprimeren en op te slaan voor verdere analyse. Het team van NC State University deed een beroep op Lenovo om deze uitdaging aan te gaan.</span></p> \n<p style=\"margin: 12pt 0in;\"><span>'Het succes van AI-systemen, met name bij deep learning, is in grote mate afhankelijk van de beschikbaarheid van big data, maar het knelpunt voor veel organisaties is een verouderde computerinfrastructuur', aldus Ranga Raju Vatsavai van NC State. 'Moderne krachtige workstations, zoals de ThinkStation P920, uitgerust met de nieuwste Intel Xeon-processors en geavanceerde GPU's in combinatie met het LiCO AI-framework van Lenovo, maken het mogelijk dat onderzoekers met een ongekende snelheid AI-oplossingen kunnen ontwikkelen en implementeren.'</span></p> \n<p style=\"margin: 12pt 0in; text-align: center;\"><span><img alt=\"\" src=\"assets/build-in-contents/images/Process.png\" style=\"color: #000000; height: 338px; width: 600px; text-align: center;\"></span></p> \n<p style=\"margin: 12pt 0in 0.0001pt;\"><span>Het team hanteerde een tweeledige aanpak om inzicht te krijgen in wat er nu gebeurt en om de toekomst beter te kunnen voorspellen. Het </span><span><a rel=\"noopener noreferrer\" href=\"https://www.lenovo.com/us/en/think-workstations/thinkstation-p-series-towers/ThinkStation-P920/p/33TS3TPP920\" target=\"_blank\"><span style=\"color: blue;\">ThinkStation P920</span></a></span><span> AI-workstation fungeert als sandbox die op de achtergrond werkt, inkomende offline gegevens doorzoekt en modellen ontwikkelt en bijwerkt op basis van de gegevens die het van over heel de wereld ontvangt. De </span><span><a rel=\"noopener noreferrer\" href=\"https://www.lenovo.com/us/en/think-workstations/thinkstation-p-series-tiny-/ThinkStation-P330-Tiny/p/33TS3TP330X\" target=\"_blank\"><span style=\"color: blue;\">ThinkStation P330 Tiny</span></a></span><span> werkt als Edge-apparaat dat gegevens van sensoren op het land verzamelt, realtime updates doorgeeft en gegevens verzamelt die weer worden teruggekoppeld. Deze voortdurende cirkelbeweging waarbij offline en realtime analyses worden samengevoegd en inzichtelijk worden gemaakt, resulteert in slimmere gegevens en daarmee in beter bruikbare oplossingen waarmee de onderzoekers van NC State de omstandigheden voor gewassen kunnen voorspellen, zelfs in de moeilijkste omstandigheden.</span></p> \n<p style=\"margin: 12pt 0in 0.0001pt; text-align: center;\"><span><img alt=\"\" src=\"assets/build-in-contents/images/Tiny.png\" style=\"color: #000000; height: 317px; width: 1024px; text-align: center;\"></span></p> \n<p style=\"margin: 12pt 0in;\"><span>Wil je meer weten over wat die gegevensoptimalisatie betekent? Dit zijn de technische details:</span></p> \n<p style=\"margin: 12pt 0in 0.0001pt;\"><em><span>De onderzoekers van NC State hebben met succes het bekende deep learning-model VGG-16 getraind voor gewasclassificatie met behulp van de satellietbeelden in hoge resolutie die zijn verzameld over North Carolina. De onbewerkte gegevens over satellietbeelden namen 6 terabyte in beslag, terwijl de trainingsgegevens slechts 91 MB innamen. Het VGG-16-model werd getraind op een P920 ThinkStation met behulp van een Intel Xeon Gold 6134-CPU en het LiCO 5.2.1-framework van Lenovo. In tegenstelling tot traditionele CPU's beschikken de moderne Intel Xeon-processors over aanvullende instructiesets die vergelijkbaar zijn met GPU's, waardoor bepaalde computertaken kunnen worden geoptimaliseerd. Zonder deze nieuwe geoptimaliseerde instructiesets duurde de berekening van het VGG-16-model ongeveer 15 uur, terwijl het geoptimaliseerde model slechts 9 uur en 19 minuten kostte. Dat betekent een aanzienlijke snelheidsverbetering per node.</span></em></p> \n<p style=\"margin-top: 12pt;\"><span>AI en machine learning maken een snellere interpretatie van gegevens mogelijk met meer effici</span><span>ë</span><span>ntie en controle. Dankzij deze workstations beschikken landbouwkundig onderzoekers nu over de artificial intelligence die ze nodig hebben om slimmer te werken en kunnen ze vertrouwen op slimme gegevens en oplossingen waarmee ze bedreigingen van de voedselveiligheid kunnen verhelpen.</span></p> \n<p><span>&nbsp;</span></p>","Author":""}}